{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "house-price-using-neural-network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhsrnxz/gLzfPXSvR/Lg3E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NahiyanNashrah/AI-Lab/blob/main/house_price_using_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsPOU5Jx74jT"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF9Ge0iYwd2z"
      },
      "source": [
        "from sklearn.datasets import load_boston\r\n",
        "boston_dataset = load_boston()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkyoAJLdwkUN"
      },
      "source": [
        "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOPxPEOUwqW8"
      },
      "source": [
        "df['PRICE'] = boston_dataset.target\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYLey0Dbwqnc",
        "outputId": "ffd163ef-49f4-4e01-be4c-d508fc4e2b48"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrNAsPwZ1_U-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ef910c4c-e11d-45ba-d02f-a638519fc43c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbch3iSZwqrR"
      },
      "source": [
        "X = df.iloc[:,0:13]\r\n",
        "Y = df.iloc[:,-1]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RotJbHZuwqtl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state=5)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmNIXO4nUc6-",
        "outputId": "4801dfab-dd9b-41e5-858f-7e7ba8094f7b"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(339, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodn3VfroawG"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo3hppXfwqxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55810176-41ed-434f-bdeb-6efbb5423198"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Dense(32, activation='relu', input_shape=(13,)),\r\n",
        "    Dense(32, activation='relu'),\r\n",
        "    Dense(1),\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_34 (Dense)             (None, 32)                448       \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,537\n",
            "Trainable params: 1,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88AmR-yvozQf"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "              loss='mse')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RjxY1Euwq2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e397b0f9-eca2-4d5b-8002-aab9ea06e9cc"
      },
      "source": [
        "model.fit(X_train, Y_train,\r\n",
        "          validation_data=(X_test, Y_test),\r\n",
        "          batch_size = 10, epochs = 400)\r\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "34/34 [==============================] - 1s 6ms/step - loss: 883.3125 - val_loss: 135.9148\n",
            "Epoch 2/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 99.9769 - val_loss: 88.3565\n",
            "Epoch 3/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 63.5347 - val_loss: 80.7159\n",
            "Epoch 4/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 57.5525 - val_loss: 77.9122\n",
            "Epoch 5/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 54.5047 - val_loss: 76.4702\n",
            "Epoch 6/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 53.6844 - val_loss: 78.7953\n",
            "Epoch 7/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 61.4898 - val_loss: 74.2686\n",
            "Epoch 8/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 51.8820 - val_loss: 73.7707\n",
            "Epoch 9/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 54.8633 - val_loss: 71.0424\n",
            "Epoch 10/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 51.7134 - val_loss: 70.3791\n",
            "Epoch 11/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 45.0766 - val_loss: 70.0367\n",
            "Epoch 12/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 54.0061 - val_loss: 78.2104\n",
            "Epoch 13/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 62.9076 - val_loss: 69.6221\n",
            "Epoch 14/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 48.2820 - val_loss: 70.0766\n",
            "Epoch 15/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 80.0307 - val_loss: 72.4913\n",
            "Epoch 16/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 48.7929 - val_loss: 68.1249\n",
            "Epoch 17/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 52.5431 - val_loss: 65.1141\n",
            "Epoch 18/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 61.9700 - val_loss: 65.8657\n",
            "Epoch 19/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 48.9815 - val_loss: 64.2068\n",
            "Epoch 20/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 62.5957 - val_loss: 64.3493\n",
            "Epoch 21/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 68.8826 - val_loss: 61.1910\n",
            "Epoch 22/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 48.9305 - val_loss: 61.8710\n",
            "Epoch 23/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 46.9508 - val_loss: 60.3799\n",
            "Epoch 24/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 46.4326 - val_loss: 67.7213\n",
            "Epoch 25/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 38.8969 - val_loss: 61.2031\n",
            "Epoch 26/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 51.1881 - val_loss: 65.4123\n",
            "Epoch 27/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 39.8739 - val_loss: 61.8615\n",
            "Epoch 28/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 46.4051 - val_loss: 59.9362\n",
            "Epoch 29/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 50.6196 - val_loss: 57.5264\n",
            "Epoch 30/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 50.0832 - val_loss: 58.7204\n",
            "Epoch 31/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 41.4227 - val_loss: 54.5290\n",
            "Epoch 32/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 42.9966 - val_loss: 55.5201\n",
            "Epoch 33/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 44.4403 - val_loss: 56.2973\n",
            "Epoch 34/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 42.6301 - val_loss: 57.8273\n",
            "Epoch 35/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 50.9465 - val_loss: 56.8571\n",
            "Epoch 36/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 49.1979 - val_loss: 52.1990\n",
            "Epoch 37/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 41.3716 - val_loss: 49.6782\n",
            "Epoch 38/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 50.4083 - val_loss: 50.7879\n",
            "Epoch 39/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 38.9277 - val_loss: 50.2554\n",
            "Epoch 40/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 35.7081 - val_loss: 54.6981\n",
            "Epoch 41/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 26.8055 - val_loss: 51.2409\n",
            "Epoch 42/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 38.2598 - val_loss: 48.1778\n",
            "Epoch 43/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 41.6527 - val_loss: 46.9744\n",
            "Epoch 44/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 40.0683 - val_loss: 47.5053\n",
            "Epoch 45/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 35.3290 - val_loss: 49.4681\n",
            "Epoch 46/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 36.2052 - val_loss: 45.1140\n",
            "Epoch 47/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 29.8845 - val_loss: 44.8508\n",
            "Epoch 48/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 35.3473 - val_loss: 43.3004\n",
            "Epoch 49/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 29.9757 - val_loss: 46.0079\n",
            "Epoch 50/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 31.6575 - val_loss: 42.5460\n",
            "Epoch 51/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 32.2374 - val_loss: 41.4818\n",
            "Epoch 52/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 34.9269 - val_loss: 47.5407\n",
            "Epoch 53/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 32.9504 - val_loss: 45.7264\n",
            "Epoch 54/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 31.7701 - val_loss: 42.5947\n",
            "Epoch 55/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 30.0683 - val_loss: 39.6429\n",
            "Epoch 56/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 31.1167 - val_loss: 39.6291\n",
            "Epoch 57/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 33.1817 - val_loss: 42.8525\n",
            "Epoch 58/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 37.8815 - val_loss: 41.6864\n",
            "Epoch 59/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 36.2442 - val_loss: 37.3296\n",
            "Epoch 60/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 32.4836 - val_loss: 36.5137\n",
            "Epoch 61/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 29.9170 - val_loss: 38.3473\n",
            "Epoch 62/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 30.1193 - val_loss: 38.3741\n",
            "Epoch 63/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 31.8167 - val_loss: 37.3536\n",
            "Epoch 64/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 27.1258 - val_loss: 34.6555\n",
            "Epoch 65/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 27.4720 - val_loss: 37.3939\n",
            "Epoch 66/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 26.7516 - val_loss: 40.2157\n",
            "Epoch 67/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 39.8190 - val_loss: 35.2023\n",
            "Epoch 68/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.4118 - val_loss: 34.8801\n",
            "Epoch 69/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.1570 - val_loss: 38.0147\n",
            "Epoch 70/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.6135 - val_loss: 37.3447\n",
            "Epoch 71/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 22.5115 - val_loss: 33.4172\n",
            "Epoch 72/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 25.1266 - val_loss: 31.7119\n",
            "Epoch 73/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.7590 - val_loss: 32.7848\n",
            "Epoch 74/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 27.6002 - val_loss: 35.7291\n",
            "Epoch 75/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 29.8114 - val_loss: 32.0542\n",
            "Epoch 76/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 28.9894 - val_loss: 32.0206\n",
            "Epoch 77/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.3303 - val_loss: 30.7095\n",
            "Epoch 78/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 31.9835 - val_loss: 32.8160\n",
            "Epoch 79/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 27.6594 - val_loss: 28.8078\n",
            "Epoch 80/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 21.5933 - val_loss: 30.0609\n",
            "Epoch 81/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 29.8739 - val_loss: 29.2519\n",
            "Epoch 82/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 22.8587 - val_loss: 30.0802\n",
            "Epoch 83/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 29.9654 - val_loss: 28.6021\n",
            "Epoch 84/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.8056 - val_loss: 29.4134\n",
            "Epoch 85/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 25.9742 - val_loss: 34.8498\n",
            "Epoch 86/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.6848 - val_loss: 29.1395\n",
            "Epoch 87/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 24.3012 - val_loss: 30.3635\n",
            "Epoch 88/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.8696 - val_loss: 31.0762\n",
            "Epoch 89/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.8741 - val_loss: 28.2712\n",
            "Epoch 90/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.5329 - val_loss: 25.7480\n",
            "Epoch 91/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 20.6770 - val_loss: 28.5235\n",
            "Epoch 92/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 28.6258 - val_loss: 26.8115\n",
            "Epoch 93/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 30.9193 - val_loss: 26.3837\n",
            "Epoch 94/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 22.0118 - val_loss: 26.5755\n",
            "Epoch 95/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.5441 - val_loss: 26.1025\n",
            "Epoch 96/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.7342 - val_loss: 25.5059\n",
            "Epoch 97/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 19.4333 - val_loss: 28.7557\n",
            "Epoch 98/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 28.5847 - val_loss: 41.3101\n",
            "Epoch 99/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.4629 - val_loss: 24.6899\n",
            "Epoch 100/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 21.5739 - val_loss: 29.8465\n",
            "Epoch 101/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.3769 - val_loss: 29.5946\n",
            "Epoch 102/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 23.5794 - val_loss: 24.9641\n",
            "Epoch 103/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 24.3175 - val_loss: 25.6251\n",
            "Epoch 104/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.3226 - val_loss: 30.1548\n",
            "Epoch 105/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 23.9878 - val_loss: 24.3966\n",
            "Epoch 106/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 20.1015 - val_loss: 22.6905\n",
            "Epoch 107/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 20.1524 - val_loss: 24.1854\n",
            "Epoch 108/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 20.7045 - val_loss: 25.5152\n",
            "Epoch 109/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 25.7202 - val_loss: 24.1647\n",
            "Epoch 110/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 22.6569 - val_loss: 28.0474\n",
            "Epoch 111/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 22.2954 - val_loss: 29.9252\n",
            "Epoch 112/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.0191 - val_loss: 30.1367\n",
            "Epoch 113/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 22.7132 - val_loss: 25.3541\n",
            "Epoch 114/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.0669 - val_loss: 24.5298\n",
            "Epoch 115/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.7382 - val_loss: 22.7807\n",
            "Epoch 116/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.6048 - val_loss: 23.9533\n",
            "Epoch 117/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.0099 - val_loss: 21.2665\n",
            "Epoch 118/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.8109 - val_loss: 24.8838\n",
            "Epoch 119/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 21.8667 - val_loss: 26.4365\n",
            "Epoch 120/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.0389 - val_loss: 27.5124\n",
            "Epoch 121/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 22.6249 - val_loss: 36.6896\n",
            "Epoch 122/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 19.0009 - val_loss: 25.6335\n",
            "Epoch 123/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.9774 - val_loss: 22.9276\n",
            "Epoch 124/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.2085 - val_loss: 21.1528\n",
            "Epoch 125/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 16.6091 - val_loss: 24.1660\n",
            "Epoch 126/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 16.7819 - val_loss: 23.3538\n",
            "Epoch 127/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 22.0258 - val_loss: 27.1843\n",
            "Epoch 128/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 20.5222 - val_loss: 23.7916\n",
            "Epoch 129/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 22.2329 - val_loss: 20.8529\n",
            "Epoch 130/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.8561 - val_loss: 25.4093\n",
            "Epoch 131/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 21.2925 - val_loss: 22.2657\n",
            "Epoch 132/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.8558 - val_loss: 19.9049\n",
            "Epoch 133/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.6385 - val_loss: 20.6523\n",
            "Epoch 134/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 20.2841 - val_loss: 23.4191\n",
            "Epoch 135/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.8078 - val_loss: 18.8156\n",
            "Epoch 136/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.1647 - val_loss: 19.9044\n",
            "Epoch 137/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.8252 - val_loss: 22.0466\n",
            "Epoch 138/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.9004 - val_loss: 22.6282\n",
            "Epoch 139/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.3852 - val_loss: 19.1359\n",
            "Epoch 140/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.2471 - val_loss: 24.2426\n",
            "Epoch 141/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 20.2216 - val_loss: 20.9031\n",
            "Epoch 142/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.7090 - val_loss: 20.2630\n",
            "Epoch 143/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.5769 - val_loss: 19.5611\n",
            "Epoch 144/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.5493 - val_loss: 22.2926\n",
            "Epoch 145/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.6084 - val_loss: 18.9595\n",
            "Epoch 146/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.1396 - val_loss: 19.3142\n",
            "Epoch 147/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.3259 - val_loss: 22.8980\n",
            "Epoch 148/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.9822 - val_loss: 23.6274\n",
            "Epoch 149/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.4363 - val_loss: 20.7227\n",
            "Epoch 150/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.9510 - val_loss: 22.2057\n",
            "Epoch 151/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.8074 - val_loss: 18.5286\n",
            "Epoch 152/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.5925 - val_loss: 19.4681\n",
            "Epoch 153/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.3241 - val_loss: 20.3823\n",
            "Epoch 154/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.8990 - val_loss: 18.8674\n",
            "Epoch 155/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 19.3834 - val_loss: 19.1740\n",
            "Epoch 156/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 16.5714 - val_loss: 19.7563\n",
            "Epoch 157/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.2785 - val_loss: 19.9565\n",
            "Epoch 158/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.4666 - val_loss: 19.7872\n",
            "Epoch 159/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 18.7297 - val_loss: 21.5750\n",
            "Epoch 160/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.8291 - val_loss: 25.6532\n",
            "Epoch 161/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 20.6185 - val_loss: 21.6230\n",
            "Epoch 162/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 21.7881 - val_loss: 18.6519\n",
            "Epoch 163/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.7617 - val_loss: 28.3196\n",
            "Epoch 164/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 22.0674 - val_loss: 26.2182\n",
            "Epoch 165/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 19.5142 - val_loss: 17.7609\n",
            "Epoch 166/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.9525 - val_loss: 22.1597\n",
            "Epoch 167/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 23.0056 - val_loss: 21.4971\n",
            "Epoch 168/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.5555 - val_loss: 24.9585\n",
            "Epoch 169/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 18.7130 - val_loss: 18.2585\n",
            "Epoch 170/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 21.3199 - val_loss: 21.0642\n",
            "Epoch 171/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.7584 - val_loss: 20.8819\n",
            "Epoch 172/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.7997 - val_loss: 20.6404\n",
            "Epoch 173/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.6047 - val_loss: 20.9244\n",
            "Epoch 174/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.7419 - val_loss: 17.8460\n",
            "Epoch 175/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.1035 - val_loss: 18.1508\n",
            "Epoch 176/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.8920 - val_loss: 21.2782\n",
            "Epoch 177/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.0102 - val_loss: 20.0263\n",
            "Epoch 178/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 25.5255 - val_loss: 20.2206\n",
            "Epoch 179/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.3641 - val_loss: 19.3961\n",
            "Epoch 180/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 22.0478 - val_loss: 18.0217\n",
            "Epoch 181/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.2540 - val_loss: 23.4462\n",
            "Epoch 182/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 18.1933 - val_loss: 17.8294\n",
            "Epoch 183/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 14.8794 - val_loss: 19.5163\n",
            "Epoch 184/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 18.5903 - val_loss: 19.3987\n",
            "Epoch 185/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.2614 - val_loss: 20.1128\n",
            "Epoch 186/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 19.7416 - val_loss: 24.2119\n",
            "Epoch 187/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.6578 - val_loss: 19.2854\n",
            "Epoch 188/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.8262 - val_loss: 17.3035\n",
            "Epoch 189/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.0770 - val_loss: 17.9550\n",
            "Epoch 190/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 20.3810 - val_loss: 19.4363\n",
            "Epoch 191/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 16.0920 - val_loss: 19.4857\n",
            "Epoch 192/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 18.2429 - val_loss: 16.9341\n",
            "Epoch 193/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.7042 - val_loss: 17.8664\n",
            "Epoch 194/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.9678 - val_loss: 20.1165\n",
            "Epoch 195/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.7380 - val_loss: 17.4983\n",
            "Epoch 196/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.8638 - val_loss: 20.1577\n",
            "Epoch 197/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.1486 - val_loss: 17.5201\n",
            "Epoch 198/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.1111 - val_loss: 23.0846\n",
            "Epoch 199/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.8946 - val_loss: 22.6899\n",
            "Epoch 200/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 18.3652 - val_loss: 21.7247\n",
            "Epoch 201/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.7093 - val_loss: 18.2590\n",
            "Epoch 202/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.4244 - val_loss: 18.0603\n",
            "Epoch 203/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 20.5373 - val_loss: 18.6152\n",
            "Epoch 204/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.1382 - val_loss: 18.2850\n",
            "Epoch 205/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.9063 - val_loss: 19.2704\n",
            "Epoch 206/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.2347 - val_loss: 18.9023\n",
            "Epoch 207/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.0879 - val_loss: 22.0281\n",
            "Epoch 208/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.4698 - val_loss: 23.5290\n",
            "Epoch 209/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.1682 - val_loss: 24.1581\n",
            "Epoch 210/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 18.9107 - val_loss: 19.0126\n",
            "Epoch 211/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.0454 - val_loss: 18.2234\n",
            "Epoch 212/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.7861 - val_loss: 18.2486\n",
            "Epoch 213/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.3042 - val_loss: 19.3256\n",
            "Epoch 214/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 14.5276 - val_loss: 20.2274\n",
            "Epoch 215/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.4314 - val_loss: 19.2626\n",
            "Epoch 216/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 16.4853 - val_loss: 19.3332\n",
            "Epoch 217/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.4559 - val_loss: 19.5571\n",
            "Epoch 218/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.3670 - val_loss: 19.5479\n",
            "Epoch 219/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 20.7976 - val_loss: 20.1309\n",
            "Epoch 220/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.4701 - val_loss: 18.7223\n",
            "Epoch 221/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 16.2929 - val_loss: 16.5499\n",
            "Epoch 222/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.7709 - val_loss: 18.6607\n",
            "Epoch 223/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.1844 - val_loss: 18.6468\n",
            "Epoch 224/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.5561 - val_loss: 20.7210\n",
            "Epoch 225/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.5935 - val_loss: 17.8349\n",
            "Epoch 226/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.3926 - val_loss: 19.4182\n",
            "Epoch 227/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.2780 - val_loss: 17.6897\n",
            "Epoch 228/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.6819 - val_loss: 24.6863\n",
            "Epoch 229/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 19.1064 - val_loss: 20.1250\n",
            "Epoch 230/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.8275 - val_loss: 18.1121\n",
            "Epoch 231/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.7897 - val_loss: 18.4505\n",
            "Epoch 232/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.3413 - val_loss: 17.8302\n",
            "Epoch 233/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.0548 - val_loss: 17.4565\n",
            "Epoch 234/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.7235 - val_loss: 18.5335\n",
            "Epoch 235/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.1663 - val_loss: 22.2987\n",
            "Epoch 236/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 12.3423 - val_loss: 16.9720\n",
            "Epoch 237/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.6566 - val_loss: 17.1281\n",
            "Epoch 238/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 17.7106 - val_loss: 20.5638\n",
            "Epoch 239/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.7966 - val_loss: 17.1132\n",
            "Epoch 240/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.0201 - val_loss: 18.1538\n",
            "Epoch 241/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.1541 - val_loss: 17.2061\n",
            "Epoch 242/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.0283 - val_loss: 17.8772\n",
            "Epoch 243/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.5322 - val_loss: 19.2806\n",
            "Epoch 244/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.0602 - val_loss: 18.3339\n",
            "Epoch 245/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.1443 - val_loss: 18.3615\n",
            "Epoch 246/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 14.3158 - val_loss: 20.5129\n",
            "Epoch 247/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.9294 - val_loss: 21.1841\n",
            "Epoch 248/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.3729 - val_loss: 17.0986\n",
            "Epoch 249/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.9134 - val_loss: 16.9317\n",
            "Epoch 250/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.3737 - val_loss: 21.5296\n",
            "Epoch 251/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.2846 - val_loss: 20.9379\n",
            "Epoch 252/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 21.8734 - val_loss: 18.0022\n",
            "Epoch 253/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.9263 - val_loss: 16.6206\n",
            "Epoch 254/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.2145 - val_loss: 17.8022\n",
            "Epoch 255/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.4383 - val_loss: 17.9154\n",
            "Epoch 256/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.8493 - val_loss: 15.7331\n",
            "Epoch 257/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.6962 - val_loss: 16.1707\n",
            "Epoch 258/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11.4619 - val_loss: 19.5850\n",
            "Epoch 259/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.3364 - val_loss: 18.3969\n",
            "Epoch 260/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 14.0701 - val_loss: 18.9309\n",
            "Epoch 261/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.2432 - val_loss: 18.3386\n",
            "Epoch 262/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.4435 - val_loss: 19.9849\n",
            "Epoch 263/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.3709 - val_loss: 16.6747\n",
            "Epoch 264/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.5343 - val_loss: 19.7920\n",
            "Epoch 265/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 14.7303 - val_loss: 23.9097\n",
            "Epoch 266/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 20.7005 - val_loss: 19.7009\n",
            "Epoch 267/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.4766 - val_loss: 18.8093\n",
            "Epoch 268/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.1279 - val_loss: 15.6539\n",
            "Epoch 269/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.2873 - val_loss: 15.9164\n",
            "Epoch 270/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.2917 - val_loss: 20.2447\n",
            "Epoch 271/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 15.9072 - val_loss: 17.7595\n",
            "Epoch 272/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.2659 - val_loss: 16.7208\n",
            "Epoch 273/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.5166 - val_loss: 17.3620\n",
            "Epoch 274/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.2090 - val_loss: 15.9169\n",
            "Epoch 275/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.6197 - val_loss: 16.3708\n",
            "Epoch 276/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.7245 - val_loss: 15.8409\n",
            "Epoch 277/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.2013 - val_loss: 16.5576\n",
            "Epoch 278/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.2826 - val_loss: 17.4330\n",
            "Epoch 279/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.2823 - val_loss: 18.2614\n",
            "Epoch 280/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.7815 - val_loss: 16.9200\n",
            "Epoch 281/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.9290 - val_loss: 16.3682\n",
            "Epoch 282/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.2315 - val_loss: 18.6520\n",
            "Epoch 283/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.4320 - val_loss: 17.4981\n",
            "Epoch 284/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.7261 - val_loss: 18.4784\n",
            "Epoch 285/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.2445 - val_loss: 17.8937\n",
            "Epoch 286/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.8503 - val_loss: 19.3468\n",
            "Epoch 287/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.9214 - val_loss: 15.9585\n",
            "Epoch 288/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.1482 - val_loss: 20.8650\n",
            "Epoch 289/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.3038 - val_loss: 15.9505\n",
            "Epoch 290/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.7874 - val_loss: 18.5224\n",
            "Epoch 291/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.2071 - val_loss: 17.5052\n",
            "Epoch 292/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.1815 - val_loss: 20.0277\n",
            "Epoch 293/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.2657 - val_loss: 17.8314\n",
            "Epoch 294/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.5956 - val_loss: 17.2745\n",
            "Epoch 295/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.4018 - val_loss: 18.5602\n",
            "Epoch 296/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11.9655 - val_loss: 17.0710\n",
            "Epoch 297/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.9356 - val_loss: 24.1629\n",
            "Epoch 298/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.7376 - val_loss: 16.4836\n",
            "Epoch 299/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.3010 - val_loss: 15.0365\n",
            "Epoch 300/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 11.5914 - val_loss: 18.0341\n",
            "Epoch 301/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.3722 - val_loss: 17.8275\n",
            "Epoch 302/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.9741 - val_loss: 16.8071\n",
            "Epoch 303/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.3011 - val_loss: 18.0114\n",
            "Epoch 304/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.4583 - val_loss: 15.7371\n",
            "Epoch 305/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.6142 - val_loss: 19.5458\n",
            "Epoch 306/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.2361 - val_loss: 16.7480\n",
            "Epoch 307/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.3767 - val_loss: 16.2521\n",
            "Epoch 308/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.8379 - val_loss: 16.1590\n",
            "Epoch 309/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.7851 - val_loss: 16.5128\n",
            "Epoch 310/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.8560 - val_loss: 17.0462\n",
            "Epoch 311/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 17.8997 - val_loss: 15.9627\n",
            "Epoch 312/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.6999 - val_loss: 15.2751\n",
            "Epoch 313/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.6918 - val_loss: 17.6092\n",
            "Epoch 314/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.0928 - val_loss: 17.4904\n",
            "Epoch 315/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.3608 - val_loss: 16.7480\n",
            "Epoch 316/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.4831 - val_loss: 18.3342\n",
            "Epoch 317/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.1932 - val_loss: 16.5772\n",
            "Epoch 318/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.5852 - val_loss: 16.0453\n",
            "Epoch 319/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.7316 - val_loss: 20.0311\n",
            "Epoch 320/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.9430 - val_loss: 16.7733\n",
            "Epoch 321/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.5784 - val_loss: 19.3160\n",
            "Epoch 322/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.0878 - val_loss: 18.3068\n",
            "Epoch 323/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.0680 - val_loss: 24.9076\n",
            "Epoch 324/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.4769 - val_loss: 16.0908\n",
            "Epoch 325/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.0945 - val_loss: 17.2973\n",
            "Epoch 326/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.2685 - val_loss: 15.2341\n",
            "Epoch 327/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.6201 - val_loss: 17.0096\n",
            "Epoch 328/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.9791 - val_loss: 17.0231\n",
            "Epoch 329/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11.4957 - val_loss: 17.1103\n",
            "Epoch 330/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.6112 - val_loss: 20.1400\n",
            "Epoch 331/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.4627 - val_loss: 18.0916\n",
            "Epoch 332/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.2155 - val_loss: 18.3804\n",
            "Epoch 333/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.2526 - val_loss: 17.8697\n",
            "Epoch 334/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.4936 - val_loss: 17.7754\n",
            "Epoch 335/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9.9873 - val_loss: 16.5464\n",
            "Epoch 336/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.8907 - val_loss: 16.8757\n",
            "Epoch 337/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.8150 - val_loss: 18.7238\n",
            "Epoch 338/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11.3216 - val_loss: 15.5609\n",
            "Epoch 339/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.8638 - val_loss: 15.6258\n",
            "Epoch 340/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.9976 - val_loss: 16.5600\n",
            "Epoch 341/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.7097 - val_loss: 20.6696\n",
            "Epoch 342/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.8084 - val_loss: 18.8533\n",
            "Epoch 343/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.5782 - val_loss: 18.4173\n",
            "Epoch 344/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.9303 - val_loss: 20.5856\n",
            "Epoch 345/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11.7851 - val_loss: 22.5273\n",
            "Epoch 346/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.7942 - val_loss: 15.2530\n",
            "Epoch 347/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.2551 - val_loss: 22.1953\n",
            "Epoch 348/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.8896 - val_loss: 15.1711\n",
            "Epoch 349/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.4234 - val_loss: 18.8201\n",
            "Epoch 350/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11.4909 - val_loss: 15.4453\n",
            "Epoch 351/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.0966 - val_loss: 19.1567\n",
            "Epoch 352/400\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 16.6905 - val_loss: 17.9603\n",
            "Epoch 353/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.2872 - val_loss: 16.2728\n",
            "Epoch 354/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.0814 - val_loss: 16.5054\n",
            "Epoch 355/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.0566 - val_loss: 21.4221\n",
            "Epoch 356/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.7816 - val_loss: 17.6591\n",
            "Epoch 357/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.1371 - val_loss: 17.5589\n",
            "Epoch 358/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8.8918 - val_loss: 15.5184\n",
            "Epoch 359/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.1787 - val_loss: 15.4656\n",
            "Epoch 360/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.4618 - val_loss: 16.1770\n",
            "Epoch 361/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.2846 - val_loss: 15.6648\n",
            "Epoch 362/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.3325 - val_loss: 17.2687\n",
            "Epoch 363/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.2641 - val_loss: 15.2368\n",
            "Epoch 364/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9.2753 - val_loss: 14.3809\n",
            "Epoch 365/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8.9526 - val_loss: 16.6826\n",
            "Epoch 366/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12.5466 - val_loss: 20.4912\n",
            "Epoch 367/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.4628 - val_loss: 15.7448\n",
            "Epoch 368/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.6884 - val_loss: 17.3549\n",
            "Epoch 369/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.1338 - val_loss: 17.3902\n",
            "Epoch 370/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12.8834 - val_loss: 17.2561\n",
            "Epoch 371/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.9447 - val_loss: 16.8874\n",
            "Epoch 372/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.0176 - val_loss: 15.8590\n",
            "Epoch 373/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.8748 - val_loss: 16.9749\n",
            "Epoch 374/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 15.5640 - val_loss: 17.6440\n",
            "Epoch 375/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13.1094 - val_loss: 15.9215\n",
            "Epoch 376/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8.5387 - val_loss: 16.7519\n",
            "Epoch 377/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9.7532 - val_loss: 17.0131\n",
            "Epoch 378/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.4776 - val_loss: 16.9689\n",
            "Epoch 379/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8.2852 - val_loss: 20.6189\n",
            "Epoch 380/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 14.2352 - val_loss: 17.6430\n",
            "Epoch 381/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.2603 - val_loss: 15.4211\n",
            "Epoch 382/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.6003 - val_loss: 18.0998\n",
            "Epoch 383/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.4775 - val_loss: 19.6107\n",
            "Epoch 384/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 16.2766 - val_loss: 16.3589\n",
            "Epoch 385/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 14.5314 - val_loss: 17.1117\n",
            "Epoch 386/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.5645 - val_loss: 17.4460\n",
            "Epoch 387/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.8512 - val_loss: 18.4526\n",
            "Epoch 388/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.9409 - val_loss: 18.1796\n",
            "Epoch 389/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.9502 - val_loss: 17.9103\n",
            "Epoch 390/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.8631 - val_loss: 16.6320\n",
            "Epoch 391/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.1012 - val_loss: 15.4851\n",
            "Epoch 392/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9.4748 - val_loss: 21.2079\n",
            "Epoch 393/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13.5184 - val_loss: 15.7588\n",
            "Epoch 394/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.5884 - val_loss: 14.7640\n",
            "Epoch 395/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.7360 - val_loss: 15.7440\n",
            "Epoch 396/400\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10.5917 - val_loss: 18.7926\n",
            "Epoch 397/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.3074 - val_loss: 16.5926\n",
            "Epoch 398/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11.3714 - val_loss: 16.7282\n",
            "Epoch 399/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9.0500 - val_loss: 15.6567\n",
            "Epoch 400/400\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10.2268 - val_loss: 14.6528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f01eea0ee48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGFhlZ5Swq5p"
      },
      "source": [
        "Y_pred = model.predict(X_test)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GNyD9jMAgBqQ",
        "outputId": "f65239c0-2481-42ac-815e-e837eef9039c"
      },
      "source": [
        "plt.scatter(Y_test, Y_pred)\r\n",
        "plt.xlabel = 'Prices'\r\n",
        "plt.ylabel = 'Predicted Prices'\r\n",
        "plt.title = 'Prices Vs Predicted Prices'\r\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45b4TxfHvNI3",
        "outputId": "e01b1f0e-14bc-482e-cb27-24a149335981"
      },
      "source": [
        "from sklearn.metrics import r2_score\r\n",
        "\r\n",
        "print('R-squared Error:', r2_score(Y_test, Y_pred))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R-squared Error: 0.8436935143268346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fhftCbLbuwEy",
        "outputId": "e18b5ffc-8e54-4f8b-fd77-818c2808967c"
      },
      "source": [
        "y = np.array(Y_test)\r\n",
        "y_p = np.array(Y_pred).flatten()\r\n",
        "df = pd.DataFrame({\"test\": y, \"predictions\": y_p})\r\n",
        "df.head(100)\r\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37.6</td>\n",
              "      <td>43.360844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.9</td>\n",
              "      <td>29.800735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.6</td>\n",
              "      <td>21.724615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.8</td>\n",
              "      <td>11.182920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.2</td>\n",
              "      <td>30.621613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>25.0</td>\n",
              "      <td>27.396187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>15.6</td>\n",
              "      <td>20.468431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>26.6</td>\n",
              "      <td>21.028505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>22.4</td>\n",
              "      <td>23.168909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>13.1</td>\n",
              "      <td>16.009552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    test  predictions\n",
              "0   37.6    43.360844\n",
              "1   27.9    29.800735\n",
              "2   22.6    21.724615\n",
              "3   13.8    11.182920\n",
              "4   35.2    30.621613\n",
              "..   ...          ...\n",
              "95  25.0    27.396187\n",
              "96  15.6    20.468431\n",
              "97  26.6    21.028505\n",
              "98  22.4    23.168909\n",
              "99  13.1    16.009552\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdUANxuXvqZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}